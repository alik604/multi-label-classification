{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ced2216-5bdb-4ad7-b9ba-a45fdb2f8b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "import gc\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, SparsePCA, LatentDirichletAllocation, TruncatedSVD # aka LSA\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import * \n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier # will not work for multi-label\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier as ET\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e44821",
   "metadata": {},
   "source": [
    "# Start\n",
    "> See other notebook for preprocessing, we start up loading proprocessed CSVs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc863f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formatted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>ASP NET Site Maps Has anyone got experience cr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Formatted\n",
       "Id                                                    \n",
       "120  ASP NET Site Maps Has anyone got experience cr..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tag\n",
       "Id      \n",
       "120  sql"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = pd.read_csv('./data/questions_preprocessed.csv', index_col=0)\n",
    "tags = pd.read_csv('./data/tags_preprocessed.csv', index_col=0)\n",
    "# questions = pd.read_csv('./data/questions_preprocessed_min3.csv', index_col=0)\n",
    "# tags = pd.read_csv('./data/tags_preprocessed_min3.csv', index_col=0)\n",
    "questions.head(1)\n",
    "tags.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions.loc[40142050].values\n",
    "# tags.loc[40142050]\n",
    "# len(X_train)\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b829b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498996/498996 [02:02<00:00, 4078.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "list_to_encode = tags.Tag.values\n",
    "mlb.fit(list_to_encode.reshape(-1,1))\n",
    "\n",
    "encoded = dict() \n",
    "for i in tqdm(tags.index.unique()): \n",
    "    input_ = tags.loc[i, 'Tag']\n",
    "    if (type(input_) is str):\n",
    "        input_ = np.array(input_)\n",
    "    else:   \n",
    "        input_ = input_.values\n",
    "    \n",
    "    ouput_ = mlb.transform(input_.reshape(-1,1))\n",
    "    ouput_ = list(np.sum(ouput_, axis=0))\n",
    "    encoded[i] = ouput_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b23521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498996/498996 [00:03<00:00, 166277.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length is 498996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_questions = []\n",
    "list_of_tags = []\n",
    "for i in tqdm(questions['Formatted'].index.unique()):\n",
    "    list_of_questions.append(questions['Formatted'][i])\n",
    "    list_of_tags.append(encoded[i])\n",
    "\n",
    "print(f'length is {len(list_of_questions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686ef682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of list_of_questions are nan. Im not sure how to deal with this.\n",
    "import math\n",
    "bad_idx = [] # [idx for idx, i in enumerate(list_of_questions) if type(i) is not str if math.isnan(i)]\n",
    "for idx, i in enumerate(list_of_questions):\n",
    "    if type(i) is not str:\n",
    "        if math.isnan(i):\n",
    "            list_of_questions[idx] = list_of_questions[idx+1]\n",
    "            list_of_tags[idx] = list_of_tags[idx+1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54677cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     questions: 539.2 MiB\n",
      "                          tags: 86.9 MiB\n",
      "                       encoded: 20.0 MiB\n",
      "             list_of_questions:  4.0 MiB\n",
      "                  list_of_tags:  4.0 MiB\n",
      "                       SCORERS:  2.2 KiB\n",
      "                          tqdm:  2.0 KiB\n",
      "                           _i1:  1.7 KiB\n",
      "                 BeautifulSoup:  1.0 KiB\n",
      "                           PCA:  1.0 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    \n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()), \n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6ab68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample question: ASP NET Site Maps Has anyone got experience creating SQL based ASP NET site map providers ve got the default XML file web sitemap working properly with my Menu and SiteMapPath controls but ll need way for the users of my site to create and modify pages dynamically need to tie page viewing permissions into the standard ASP NET membership system as well \n",
      "\n",
      "Number of tags: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Sample question: {list_of_questions[0]}\\n')\n",
    "print(f'Number of tags: {sum(list_of_tags[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae36a3b",
   "metadata": {},
   "source": [
    "# Experiment 1: Encoding with Tokenizer, padding sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb78749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(list_of_questions, list_of_tags, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] = np.array(y_train[i])\n",
    "    \n",
    "y_test = np.asarray(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    y_test[i] = np.array(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77fa3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqueWords = set() # same seed as list which we cast to set at end\n",
    "# for q in list_of_questions[:500000]:\n",
    "#     for word in q.split():\n",
    "#         uniqueWords.add(word.lower()) \n",
    "# 309411 unique words in first 500000 questions\n",
    "num_words = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06292bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ref https://stackabuse.com/python-for-nlp-multi-label-text-classification-with-keras/\n",
    "tokenizer = Tokenizer(char_level=False, num_words=num_words, filters='!\"()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n') # #$%&\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# vocab_size # 309411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de9088c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to get the pad_sequences's max length. perhaps it's wise to chose the median + IQR*1.5, 167.399044579605, \n",
      "IQR: 122 | mean: 167.40 | median: 122.0 | upper bound: 167.399044579605\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_lengths = np.sort(np.asarray([len(i) for i in X_train]))\n",
    "IQR = sorted_lengths[3*len(sorted_lengths)//4] - sorted_lengths[1*len(sorted_lengths)//4]\n",
    "upper_bound = np.mean(sorted_lengths)\n",
    "# upper_bound = np.median(sorted_lengths) + IQR*1.5\n",
    "\n",
    "print(f\"We need to get the pad_sequences's max length. perhaps it's wise to chose the median + IQR*1.5, {upper_bound}, \")\n",
    "print(f'IQR: {IQR} | mean: {np.mean(sorted_lengths):.2f} | median: {np.median(sorted_lengths)} | upper bound: {upper_bound}')\n",
    "\n",
    "_ = plt.hist(sorted_lengths, bins=20)\n",
    "_ = plt.vlines(upper_bound, -5000, 2000, linestyles='dashed', colors='r', label='Upper Bound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8ee650",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = min(int(upper_bound), 200)\n",
    "X_train = pad_sequences(X_train, padding='post', truncating='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test,   padding='post', truncating='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff21cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.79% change in of vocab size with lemmatization on 1 precent of data\n"
     ]
    }
   ],
   "source": [
    "# len(tokenizer.word_index.keys())\n",
    "## dont on `X_train` from test_size=0.99 \n",
    "# with    lemmatization 35659\n",
    "# without lemmatization 37851 \n",
    "\n",
    "print(f'{100*(35659-37851)/37851:.2f}% change in of vocab size with lemmatization on 1 precent of data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f7dc6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(y_test, y_pred, clf=None):\n",
    "    with warnings.catch_warnings():\n",
    "        # print(\"Clf: \", clf.__class__.__name__)\n",
    "        print(f\"Accuracy score: {accuracy_score(y_true=y_test, y_pred=y_pred)}\")\n",
    "        print(f\"Recall score: {recall_score(y_true=y_test, y_pred=y_pred, average='weighted')}\")\n",
    "        print(f\"Precision score: {precision_score(y_true=y_test, y_pred=y_pred, average='weighted')}\")\n",
    "        f1 = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f2a9e",
   "metadata": {},
   "source": [
    "## Experiment 1 assessment - sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba5fd959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf:  ExtraTreesClassifier\n",
      "Accuracy score: 7.014028056112224e-05\n",
      "Recall score: 9.871059288049849e-05\n",
      "Precision score: 0.1398204701091986\n",
      "F1 score: 0.0001972268287894712\n",
      "Train score: 0.9999899798595177\n",
      "Test score:  7.014028056112224e-05\n",
      "Time taken for ExtraTreesClassifier was 242.43\n",
      "\n",
      "\n",
      "Clf:  RandomForestClassifier\n",
      "Accuracy score: 0.0010320641282565131\n",
      "Recall score: 0.0010488000493552964\n",
      "Precision score: 0.20879851674301186\n",
      "F1 score: 0.002076166706540318\n",
      "Train score: 0.879317428030341\n",
      "Test score:  0.0010320641282565131\n",
      "Time taken for RandomForestClassifier was 326.77\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "# clfs.append(DecisionTreeClassifier(random_state=42))\n",
    "clfs.append(ExtraTreesClassifier(n_estimators=15, random_state=42, n_jobs=-1))\n",
    "clfs.append(RandomForestClassifier(n_estimators=15, random_state=42, n_jobs=-1))\n",
    "# clfs.append(RadiusNeighborsClassifier(n_jobs=-1)) # takes a while\n",
    "# clfs.append(KNeighborsClassifier(n_neighbors=10, n_jobs=-1)) # untested too long\n",
    "\n",
    "for clf in clfs:\n",
    "    start = time.time()\n",
    "    _ = gc.collect()\n",
    "    _ = clf.fit(X_train, y_train)\n",
    "    print(\"Clf: \", clf.__class__.__name__)\n",
    "    F1 = print_score(y_test, clf.predict(X_test), clf)\n",
    "    print(f'Train score: {clf.score(X_train, y_train)}')\n",
    "    print(f'Test score:  {clf.score(X_test, y_test)}')\n",
    "\n",
    "    print(f'Time taken for {clf.__class__.__name__} was {time.time()-start:.2f}\\n\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e68703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf:  MLPClassifier\n",
      "Accuracy score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "F1 score: 0.0\n",
      "Train score: 0.0\n",
      "Test score:  0.0\n",
      "Time taken for MLPClassifier was 199.30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x216 with 0 Axes>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26362a461c0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(200, 100), random_state=42, max_iter=60)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Clf: \", clf.__class__.__name__)\n",
    "F1 = print_score(y_test, clf.predict(X_test), clf)\n",
    "print(f'Train score: {clf.score(X_train, y_train)}')\n",
    "print(f'Test score:  {clf.score(X_test, y_test)}')\n",
    "    \n",
    "print(f'Time taken for {clf.__class__.__name__} was {time.time()-start:.2f}')\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(clf.loss_curve_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb1c55",
   "metadata": {},
   "source": [
    "### In depth Eval of MLPClassifier, via argmax of `clf.predict_proba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c98c185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.05029058116232465\n",
      "Recall score: 0.129113455487692\n",
      "Precision score: 0.0484842678766208\n",
      "F1 score: 0.048090358807756674\n",
      "\n",
      "y_pred: java\n",
      "y_test: java\n",
      "\n",
      "\n",
      "y_pred: c#, java\n",
      "y_test: java, swing\n",
      "\n",
      "\n",
      "y_pred: c#, java\n",
      "y_test: html5, javascript\n",
      "\n",
      "\n",
      "y_pred: c#, java\n",
      "y_test: mysql, php\n",
      "\n",
      "\n",
      "y_pred: java\n",
      "y_test: spring\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "y_pred_same_number_of_tags = [] # if average tags is 2.5, we are at a disadvantage if we do 2 or 3 tags.\n",
    "for i in range(len(y_pred)):  \n",
    "    best = y_pred[i].argsort()\n",
    "    y_pred_ = np.zeros(y_pred.shape[1])\n",
    "    number_of_tags = np.sum(y_test[i])\n",
    "    y_pred_[best[-number_of_tags:]] = 1\n",
    "    y_pred_same_number_of_tags.append(y_pred_)\n",
    "    \n",
    "_ = print_score(y_test, y_pred_same_number_of_tags) \n",
    "print(\"\")\n",
    "\n",
    "for i in range(5): # how many examples to print\n",
    "    idx = np.random.randint(0, len(y_pred))\n",
    "    print(\"y_pred:\",', '.join(mlb.inverse_transform(y_pred_same_number_of_tags[idx].reshape(1,-1))[0]))\n",
    "    print(\"y_test:\",', '.join(mlb.inverse_transform(y_test[idx].reshape(1,-1))[0]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e8e3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dim reduction was pointless\n",
    "\n",
    "# print(f'shape of X_train: {X_train.shape}')\n",
    "\n",
    "# # from sklearn.decomposition import LatentDirichletAllocation # took ovr 10 mins\n",
    "# # dcomp = LatentDirichletAllocation(n_components=100, random_state=42)\n",
    "\n",
    "# dcomp = PCA(n_components=100, random_state=42) # , iterated_power=30\n",
    "# dcomp.fit(X_train)\n",
    "# print(f'explained variance ratio: {sum(dcomp.explained_variance_ratio_):.2f}')\n",
    "# X_train_transformed = dcomp.transform(X_train)\n",
    "# X_test_transformed = dcomp.transform(X_test)\n",
    "\n",
    "# print(f'shape of X_train_transformed: {X_train_transformed.shape}')\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# clf = MLPClassifier(random_state=42, max_iter=140)\n",
    "# clf = clf.fit(X_train_transformed, y_train)\n",
    "# print(\"Clf: \", clf.__class__.__name__)\n",
    "\n",
    "# print_score(y_test, clf.predict(X_test_transformed), clf)\n",
    "# print(f'Train score: {clf.score(X_train_transformed, y_train)}')\n",
    "# print(f'Test score:  {clf.score(X_test_transformed, y_test)}')\n",
    "    \n",
    "# print(f'Time taken for {clf.__class__.__name__} was {time.time()-start:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d90b8",
   "metadata": {},
   "source": [
    "## Experiment 1 assessment - Basic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9b3cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "target_size = len(mlb.classes_)\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4273eded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portion of words in embedding: 0.2708\n"
     ]
    }
   ],
   "source": [
    "## Build glove embdedding matrix\n",
    "embeddings_dictionary = dict()\n",
    "# glove_file = open('.\\data\\glove.42B.300d.txt', encoding=\"utf8\")\n",
    "glove_file = open('C:\\\\glove.42B.300d.txt', encoding=\"utf8\")\n",
    "for line in glove_file: # longer, by far\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "num_words_in_embedding = 0\n",
    "# embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "embedding_matrix = np.random.normal(scale=0.6, size=((vocab_size, embedding_dim)))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        num_words_in_embedding += 1\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "        \n",
    "print(f'portion of words in embedding: {num_words_in_embedding/vocab_size:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aeaa088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input\n",
    "# del model, opt, lr\n",
    "\n",
    "loss = []\n",
    "acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "checkpoint_file = 'ModelCheckpoint.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "95bd83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = mlb.classes_.shape[0]\n",
    "model = Sequential() ;_=gc.collect()\n",
    "model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "model.add((Bidirectional(LSTM(64, return_sequences=True))))\n",
    "model.add(Dropout(0.05)) # technically not appropriate for a LSTM. recc_dropout is not on CuDNN\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(output_dim, activation='sigmoid')) # , activation='softmax')\n",
    "\n",
    "opt = Adam(learning_rate=0.003)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc']) # categorical_crossentropy\n",
    "lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
    "cp = ModelCheckpoint(filepath=checkpoint_file, monitor='val_acc', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c478010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "476/476 [==============================] - 25s 44ms/step - loss: 0.0814 - acc: 0.0678 - val_loss: 0.0728 - val_acc: 0.0773 - lr: 0.0030\n",
      "Epoch 2/20\n",
      "476/476 [==============================] - 19s 40ms/step - loss: 0.0719 - acc: 0.0869 - val_loss: 0.0667 - val_acc: 0.1552 - lr: 0.0030\n",
      "Epoch 3/20\n",
      "476/476 [==============================] - 20s 41ms/step - loss: 0.0569 - acc: 0.2938 - val_loss: 0.0452 - val_acc: 0.4245 - lr: 0.0030\n",
      "Epoch 4/20\n",
      "476/476 [==============================] - 19s 41ms/step - loss: 0.0416 - acc: 0.4828 - val_loss: 0.0369 - val_acc: 0.5135 - lr: 0.0030\n",
      "Epoch 5/20\n",
      "476/476 [==============================] - 20s 42ms/step - loss: 0.0352 - acc: 0.5484 - val_loss: 0.0326 - val_acc: 0.5550 - lr: 0.0030\n",
      "Epoch 6/20\n",
      "476/476 [==============================] - 19s 40ms/step - loss: 0.0318 - acc: 0.5770 - val_loss: 0.0309 - val_acc: 0.5613 - lr: 0.0030\n",
      "Epoch 7/20\n",
      "476/476 [==============================] - 20s 41ms/step - loss: 0.0298 - acc: 0.5921 - val_loss: 0.0302 - val_acc: 0.5705 - lr: 0.0030\n",
      "Epoch 8/20\n",
      "476/476 [==============================] - 20s 41ms/step - loss: 0.0285 - acc: 0.6009 - val_loss: 0.0296 - val_acc: 0.5711 - lr: 0.0030\n",
      "Epoch 9/20\n",
      "476/476 [==============================] - 20s 42ms/step - loss: 0.0273 - acc: 0.6085 - val_loss: 0.0291 - val_acc: 0.5756 - lr: 0.0030\n",
      "Epoch 10/20\n",
      "476/476 [==============================] - 16s 34ms/step - loss: 0.0263 - acc: 0.6169 - val_loss: 0.0289 - val_acc: 0.5741 - lr: 0.0030\n",
      "Epoch 11/20\n",
      "476/476 [==============================] - 16s 35ms/step - loss: 0.0254 - acc: 0.6249 - val_loss: 0.0294 - val_acc: 0.5756 - lr: 0.0030\n",
      "Epoch 12/20\n",
      "475/476 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.6280\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
      "476/476 [==============================] - 20s 42ms/step - loss: 0.0246 - acc: 0.6280 - val_loss: 0.0289 - val_acc: 0.5828 - lr: 0.0030\n",
      "Epoch 13/20\n",
      "476/476 [==============================] - 16s 33ms/step - loss: 0.0228 - acc: 0.6442 - val_loss: 0.0287 - val_acc: 0.5805 - lr: 9.0000e-04\n",
      "Epoch 14/20\n",
      "476/476 [==============================] - 16s 33ms/step - loss: 0.0221 - acc: 0.6507 - val_loss: 0.0291 - val_acc: 0.5777 - lr: 9.0000e-04\n",
      "Epoch 15/20\n",
      "476/476 [==============================] - ETA: 0s - loss: 0.0218 - acc: 0.6530\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
      "476/476 [==============================] - 15s 32ms/step - loss: 0.0218 - acc: 0.6530 - val_loss: 0.0295 - val_acc: 0.5781 - lr: 9.0000e-04\n",
      "Epoch 16/20\n",
      "476/476 [==============================] - 16s 33ms/step - loss: 0.0210 - acc: 0.6608 - val_loss: 0.0297 - val_acc: 0.5806 - lr: 2.7000e-04\n",
      "Epoch 17/20\n",
      "475/476 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.6620\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 8.099999686237424e-05.\n",
      "476/476 [==============================] - 16s 34ms/step - loss: 0.0208 - acc: 0.6621 - val_loss: 0.0299 - val_acc: 0.5769 - lr: 2.7000e-04\n",
      "Epoch 18/20\n",
      "476/476 [==============================] - 16s 34ms/step - loss: 0.0205 - acc: 0.6633 - val_loss: 0.0301 - val_acc: 0.5805 - lr: 8.1000e-05\n",
      "Epoch 19/20\n",
      "475/476 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.6662\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-05.\n",
      "476/476 [==============================] - 15s 32ms/step - loss: 0.0205 - acc: 0.6662 - val_loss: 0.0302 - val_acc: 0.5783 - lr: 8.1000e-05\n",
      "Epoch 20/20\n",
      "476/476 [==============================] - 15s 32ms/step - loss: 0.0204 - acc: 0.6659 - val_loss: 0.0302 - val_acc: 0.5799 - lr: 2.4300e-05\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model(\"keras_lstm.h5\")\n",
    "# model.layers[0].trainable = True\n",
    "history = model.fit(X_train, y_train, validation_split=0.05, epochs=10, batch_size=256, verbose=1, callbacks=[lr, cp])\n",
    "loss.extend(history.history['loss'])\n",
    "acc.extend(history.history['acc'])\n",
    "val_loss.extend(history.history['val_loss'])\n",
    "val_acc.extend(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e2a07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"keras_lstm_min_3_score.h5\" )\n",
    "# model.save(\"keras_lstm_all_scores.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "04f9b990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6018110850897737\n",
      "Recall score: 0.7138925218138163\n",
      "Precision score: 0.709068864522389\n",
      "F1 score: 0.7091016493667925\n"
     ]
    }
   ],
   "source": [
    "def test_keras_model(print_sample=False, X_test=X_test, model=model, y_test=y_test, topN=2):\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # for thres in range(3, 5):\n",
    "    #     print(f'rounding threshold: {thres/10}')\n",
    "    #     y_pred_ = np.array(np.array(y_pred) > thres/10, dtype=float)\n",
    "    #     _ = print_score(y_test, y_pred_)\n",
    "        # print('\\n')\n",
    "\n",
    "\n",
    "    ## y_pred = np.array(np.array(y_pred) > .3, dtype=float)\n",
    "    # topN = topN\n",
    "    # y_pred_top = np.zeros_like(y_pred)\n",
    "    # for i in range(y_pred.shape[0]):\n",
    "    #     best = y_pred[i].argsort()\n",
    "    #     y_pred_ = np.zeros(y_pred.shape[1])\n",
    "    #     y_pred_[best[-topN:]] = 1\n",
    "    #     y_pred_top[i] = y_pred_\n",
    "\n",
    "    # print(f'\\ntopN: {topN}')\n",
    "    # _ = print_score(y_test, y_pred_top)\n",
    "    \n",
    "    y_pred_same_number_of_tags = [] # if average tags is 2.5, we are at a disadvantage if we do 2 or 3 tags.\n",
    "    \n",
    "    for i in range(len(y_pred)):  \n",
    "        best = y_pred[i].argsort()\n",
    "        y_pred_ = np.zeros(y_pred.shape[1])\n",
    "        number_of_tags = np.sum(y_test[i])\n",
    "        y_pred_[best[-number_of_tags:]] = 1\n",
    "        y_pred_same_number_of_tags.append(y_pred_)\n",
    "        \n",
    "    _ = print_score(y_test, y_pred_same_number_of_tags) \n",
    "\n",
    "    # if print_sample:\n",
    "    for i in range(print_sample):\n",
    "        idx = np.random.randint(0, len(y_pred))\n",
    "        print(\"y_pred:\",', '.join(mlb.inverse_transform(y_pred_same_number_of_tags[idx].reshape(1,-1))[0]))\n",
    "        print(\"y_test:\",', '.join(mlb.inverse_transform(y_test[idx].reshape(1,-1))[0]))\n",
    "        print('\\n')\n",
    "\n",
    "test_keras_model(print_sample=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "67eb7512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "476/476 [==============================] - 17s 34ms/step - loss: 0.0203 - acc: 0.6657 - val_loss: 0.0302 - val_acc: 0.5792 - lr: 2.4300e-05\n",
      "Epoch 2/4\n",
      "476/476 [==============================] - 16s 34ms/step - loss: 0.0203 - acc: 0.6666 - val_loss: 0.0303 - val_acc: 0.5786 - lr: 2.4300e-05\n",
      "Epoch 3/4\n",
      "476/476 [==============================] - ETA: 0s - loss: 0.0203 - acc: 0.6660\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "476/476 [==============================] - 16s 34ms/step - loss: 0.0203 - acc: 0.6660 - val_loss: 0.0303 - val_acc: 0.5786 - lr: 2.4300e-05\n",
      "Epoch 4/4\n",
      "476/476 [==============================] - 16s 34ms/step - loss: 0.0203 - acc: 0.6675 - val_loss: 0.0303 - val_acc: 0.5785 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "_=gc.collect()\n",
    "model.layers[0].trainable = True\n",
    "history = model.fit(X_train, y_train, validation_split=0.05, epochs=5, batch_size=256, verbose=1, callbacks=[lr, cp])\n",
    "# model.save(\"keras_lstm_min_3_score.h5\")\n",
    "\n",
    "loss.extend(history.history['loss'])\n",
    "acc.extend(history.history['acc'])\n",
    "val_loss.extend(history.history['val_loss'])\n",
    "val_acc.extend(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d10cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1902/1902 [==============================] - 48s 25ms/step - loss: 0.0214 - acc: 0.6572 - val_loss: 0.0301 - val_acc: 0.5761 - lr: 5.0000e-04\n",
      "Epoch 2/5\n",
      "1902/1902 [==============================] - 49s 26ms/step - loss: 0.0209 - acc: 0.6605 - val_loss: 0.0304 - val_acc: 0.5744 - lr: 5.0000e-04\n",
      "Epoch 3/5\n",
      "1902/1902 [==============================] - ETA: 0s - loss: 0.0205 - acc: 0.6649\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1902/1902 [==============================] - 50s 26ms/step - loss: 0.0205 - acc: 0.6649 - val_loss: 0.0309 - val_acc: 0.5738 - lr: 5.0000e-04\n",
      "Epoch 4/5\n",
      "1902/1902 [==============================] - 48s 25ms/step - loss: 0.0197 - acc: 0.6699 - val_loss: 0.0312 - val_acc: 0.5741 - lr: 1.5000e-04\n",
      "Epoch 5/5\n",
      "1900/1902 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.6716\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.500000213738531e-05.\n",
      "1902/1902 [==============================] - 47s 25ms/step - loss: 0.0195 - acc: 0.6716 - val_loss: 0.0313 - val_acc: 0.5739 - lr: 1.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# decrease LR and batch size\n",
    "_=gc.collect()\n",
    "keras.backend.set_value(model.optimizer.lr, 0.0005)\n",
    "model.layers[0].trainable = True\n",
    "history = model.fit(X_train, y_train, validation_split=0.05, epochs=5, batch_size=64, verbose=1, callbacks=[lr, cp])\n",
    "model.save(\"keras_lstm_min_3_score.h5\")\n",
    "\n",
    "loss.extend(history.history['loss'])\n",
    "acc.extend(history.history['acc'])\n",
    "val_loss.extend(history.history['val_loss'])\n",
    "val_acc.extend(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d16d29",
   "metadata": {},
   "source": [
    "#### This will print the top five most likely tags, and then the 4 metrics, in a manner such the the network preds the same number of tags as the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f03b7569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: c, c++, debugging, gcc, linux\n",
      "y_test: c, gcc\n",
      "\n",
      "\n",
      "y_pred: ios, iphone, objective-c, swift, xcode\n",
      "y_test: ios, xcode\n",
      "\n",
      "\n",
      "y_pred: android, image, java, security, xml\n",
      "y_test: android\n",
      "\n",
      "\n",
      "y_pred: .net, c#, c++, java, oop\n",
      "y_test: java, oop\n",
      "\n",
      "\n",
      "y_pred: android, eclipse, image, java, xml\n",
      "y_test: android\n",
      "\n",
      "\n",
      "Accuracy score: 0.6074004683840749\n",
      "Recall score: 0.7184016865447306\n",
      "Precision score: 0.7106922187288004\n",
      "F1 score: 0.7064893569114334\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_file)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "topN = 5\n",
    "y_pred_top = np.zeros_like(y_pred)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    best = y_pred[i].argsort()\n",
    "    y_pred_ = np.zeros(y_pred.shape[1])\n",
    "    y_pred_[best[-topN:]] = 1\n",
    "    y_pred_top[i] = y_pred_\n",
    "\n",
    "for i in range(5): # how many examples to print\n",
    "    idx = np.random.randint(0, len(y_pred))\n",
    "    print(\"y_pred:\",', '.join(mlb.inverse_transform(y_pred_top[idx].reshape(1,-1))[0]))\n",
    "    print(\"y_test:\",', '.join(mlb.inverse_transform(y_test[idx].reshape(1,-1))[0]))\n",
    "    print('\\n')\n",
    "    \n",
    "\n",
    "y_pred_same_number_of_tags = [] # if average tags is 2.5, we are at a disadvantage if we do 2 or 3 tags.\n",
    "for i in range(len(y_pred)):  \n",
    "    best = y_pred[i].argsort()\n",
    "    y_pred_ = np.zeros(y_pred.shape[1])\n",
    "    number_of_tags = np.sum(y_test[i])\n",
    "    y_pred_[best[-number_of_tags:]] = 1\n",
    "    y_pred_same_number_of_tags.append(y_pred_)\n",
    "    \n",
    "_ = print_score(y_test, y_pred_same_number_of_tags) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b8756",
   "metadata": {},
   "source": [
    "```\n",
    "on the all scores dataset \"questions_preprocessed.csv\"\n",
    "2963/2963 [==============================] - 85s 29ms/step - loss: 0.0199 - acc: 0.6533 - val_loss: 0.0242 - val_acc: 0.6135 - lr: 5.0000e-04\n",
    "\n",
    "Accuracy score: 0.6504909819639279\n",
    "Recall score: 0.7615028687766056\n",
    "Precision score: 0.7574494222705919\n",
    "F1 score: 0.7544918807953225\n",
    "\n",
    "\n",
    "on the min 3 scores dataset \"questions_preprocessed_min3.csv\"\n",
    "\n",
    "1902/1902 [==============================] - 47s 25ms/step - loss: 0.0195 - acc: 0.6716 - val_loss: 0.0313 - val_acc: 0.5739 - lr: 1.5000e-04\n",
    "\n",
    "Accuracy score: 0.6123965651834504\n",
    "Recall score: 0.7221690839173125\n",
    "Precision score: 0.7139613396235852\n",
    "F1 score: 0.714711189087093\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f317e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a556b5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LSTM w/ GloVe Loss BCE')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16b5e98ef10>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16b5e98e9a0>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16b5e981fa0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('LSTM w/ GloVe Loss BCE')\n",
    "plt.plot(loss, label='train loss')\n",
    "plt.plot(val_loss, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73392844",
   "metadata": {},
   "source": [
    "### The torch model failed to train\n",
    "> code is left to show proof of work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def minimal_code_example():\n",
    "#     m = nn.Sigmoid()\n",
    "#     loss = nn.BCELoss()\n",
    "\n",
    "#     input = torch.randn(3, requires_grad=True)\n",
    "#     target = torch.empty(3).random_(2)\n",
    "\n",
    "#     lin = torch.nn.Linear(3,3)\n",
    "#     optimizer = optim.SGD(lin.parameters(), lr = 0.001)\n",
    "\n",
    "#     print(f'lin(input)    = {lin(input).detach().numpy()}')\n",
    "#     print(f'target        = {target.detach().numpy()}')\n",
    "    \n",
    "#     for i in range(500):\n",
    "#         output = loss(m(lin(input)), target)\n",
    "#         # optimizer.clear_grad()\n",
    "#         output.backward()\n",
    "#         optimizer.step()\n",
    "#         # output.item()\n",
    "\n",
    "#     print(f'lin(input)    = {lin(input).detach().numpy()}')\n",
    "#     print(f'm(lin(input)) = {m(lin(input)).detach().numpy()}')\n",
    "#     print(f'target        = {target.detach().numpy()}')\n",
    "    \n",
    "\n",
    "# minimal_code_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7475df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train).to(device)\n",
    "X_test_tensor = torch.tensor(X_test).to(device)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "embedding_matrix = torch.tensor(embedding_matrix)\n",
    "(vocab_size, embedding_dim)\n",
    "\n",
    "# idx = 64\n",
    "# X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = X_train_tensor[:idx], X_test_tensor[:idx], y_train_tensor[:idx], y_test_tensor[:idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from my past code https://github.com/alik604/cyber-security/blob/master/Intrusion-Detection/UNSW_NB15%20-%20PyTorch%20feature%20selection%20via%20L1%20regularization%20on%20layer_1.ipynb\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, target_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim*maxlen, target_size)\n",
    "        self.linear = nn.Linear(target_size, target_size)\n",
    "        self.linear_out = nn.Linear(target_size, target_size)\n",
    "        \n",
    "        self.embeddings.load_state_dict({'weight': embedding_matrix})\n",
    "        # self.embeddings.weight.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # print(f'inputs: {inputs.size()}')\n",
    "        \n",
    "        out = self.embeddings(inputs) \n",
    "        # print(f'embeds: {out.size()}')\n",
    "        \n",
    "        out, _ = self.lstm(out.view(len(inputs), 1, -1))\n",
    "        # print(f'lstm: {out.size()}')\n",
    "        \n",
    "        out = out.view(len(inputs), -1)\n",
    "        out = F.relu(self.linear(out))\n",
    "        # print(f'linear: {out.size()}')\n",
    "        \n",
    "        out = self.linear_out(out)\n",
    "        # print(f'linear_out: {out.size()}')\n",
    "        \n",
    "        return F.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc626e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 0 # 10 # disable. model will not train\n",
    "batch_size = 128\n",
    "batch_size_test = 512\n",
    "LR = 0.0005 # 0.001\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "best_f1 = -1\n",
    "\n",
    "criterion = nn.BCELoss() # nn.CrossEntropyLoss()\n",
    "model = LSTM(vocab_size, embedding_dim, target_size).to(device)\n",
    "try:\n",
    "    model.load_state_dict(torch.load('model.pt'))\n",
    "except:\n",
    "    print('model.pt not found')\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63884ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    if epoch == int(num_epochs/2):\n",
    "        model.embeddings.weight.requires_grad = True\n",
    "        \n",
    "    for i in range(0, X_train_tensor.shape[0], batch_size):\n",
    "\n",
    "        x = X_train_tensor[i:i+batch_size]#.to(device)\n",
    "        y = y_train_tensor[i:i+batch_size]#.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)     \n",
    "        \n",
    "        # print(f'outputs: {outputs.size()} | {y.dtype}')\n",
    "        # print(f'y:       {y.size()} | {y.dtype}')        \n",
    "        # print(outputs[0])\n",
    "        # print(y[0])\n",
    "        # break\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        round_ = torch.round(outputs)\n",
    "        number_of_predictions_per_sample = torch.sum(round_, -1)\n",
    "        number_of_predictions_per_batch = torch.sum(number_of_predictions_per_sample > 1)\n",
    "        if  number_of_predictions_per_batch < batch_size: # there must be a pred for each sample, the network thinks it can preform by marely guessing all 0s\n",
    "            loss = loss + (batch_size - number_of_predictions_per_batch)/batch_size  # 0.01 * torch.norm(model.embeddings.weight, 1) \n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        # break\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        l = X_test_tensor.shape[0]\n",
    "        y_pred = np.zeros((l, target_size))\n",
    "        for i in range(0, l, batch_size_test):\n",
    "            with torch.no_grad(): \n",
    "                x = X_test_tensor[i:i+batch_size_test]#.to(device)\n",
    "                y = y_test_tensor[i:i+batch_size_test]#.to(device)\n",
    "                \n",
    "                outputs = model(x)\n",
    "                y_pred[i:min(i+batch_size_test, l)] = outputs.detach().cpu().numpy()  \n",
    "                loss = criterion(outputs, y) \n",
    "                test_loss += loss.item()\n",
    "                \n",
    "        test_losses.append(test_loss)\n",
    "        y_pred = np.array(y_pred > 0.5, dtype=float) # TODO if this was used, there is better code for this used with the keras model\n",
    "        \n",
    "        print(f'[{epoch+1}/{num_epochs}] | Train Loss {train_loss/len(X_train_tensor):.6f} | Test Loss {test_loss/len(X_test_tensor):.6f}')\n",
    "        \n",
    "        f1 = print_score(y_test_tensor.detach().cpu().numpy(), y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model.state_dict(), 'model.pt')\n",
    "            print('\\tWeights Saved')\n",
    "    else:\n",
    "        print(f'[{epoch+1}/{num_epochs}] | Train Loss {train_loss/len(X_train_tensor):.6f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# del X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, model, optimizer, criterion\n",
    "\n",
    "# plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    # y_pred_ = []\n",
    "    y_pred_ = np.zeros((X.shape[0], 101))\n",
    "    with torch.no_grad(): \n",
    "        for i in range(0, X.shape[0], 512):\n",
    "            with torch.no_grad(): \n",
    "                x = X[i:i+512].to(device)\n",
    "                y_pred = model(x).detach().cpu().numpy()      \n",
    "                y_pred_[i:min(i+512, X.shape[0])] = y_pred #.extend(x)\n",
    "    return y_pred_\n",
    "\n",
    "sample = 64\n",
    "y_pred = predict(X_test_tensor[:sample])\n",
    "y_pred = np.array(np.array(y_pred) > 0.5, dtype=float)\n",
    "print_score(y_test[:sample], y_pred[:sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba8f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "897a2211",
   "metadata": {},
   "source": [
    "# Expirement 2: Encoding with TfidfVectorizer\n",
    "> the following stats are for the `tags_preprocessed.csv` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c5a5a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features is 5000\n"
     ]
    }
   ],
   "source": [
    "# https://www.linkedin.com/pulse/count-vectorizers-vs-tfidf-natural-language-processing-sheel-saket\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "# Equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "# would be cool to try tri-grams. \n",
    "stop_words = \"english\"\n",
    "stop_words = None # there are maybe 300 stop words, and thousands of other features. i'm inclined to keep them around\n",
    "max_features = 374513 # 374513 for unigrams without min_df\n",
    "max_features = 5000  # realistic? \n",
    "min_df=5   # 108967 \n",
    "min_df=50  # 20671\n",
    "min_df=200 # 8908\n",
    "min_df=1000# 3385\n",
    "max_df=0.90 # 8908 -> 8906\n",
    "# max_df=0.85 # 8906 -> 8906\n",
    "\n",
    "\n",
    "### if on tags_preprocessed_min3.csv dataset, use this\n",
    "min_df=318 # 3378\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', ngram_range=(1, 1), stop_words=stop_words, max_features=max_features, min_df=min_df, max_df=max_df)\n",
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "docs       = vectorizer.fit_transform(list_of_questions)\n",
    "features   = vectorizer.get_feature_names()\n",
    "print(f'The number of features is {len(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f63ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand = random.randint(0, len(features)-10)\n",
    "# features[rand: rand+10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfe6b03",
   "metadata": {},
   "source": [
    "### Note the `test_size` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb6054cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples is 498996 \n",
      "The number of features is 5000\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of samples is {docs.shape[0]} \\nThe number of features is {docs.shape[1]}')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(docs, list_of_tags, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] = np.array(y_train[i])\n",
    "    \n",
    "y_test = np.asarray(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    y_test[i] = np.array(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25546d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'shape of X_train: {X_train.shape}')\n",
    "\n",
    "# # dcomp = SparsePCA(n_components=200, max_iter=1, n_jobs=-1, random_state=42) # poor performance \n",
    "# dcomp = TruncatedSVD(n_components=1500, n_iter=20, random_state=42) # \n",
    "\n",
    "# dcomp.fit(X_train.toarray())\n",
    "# print(f'explained variance ratio: {sum(dcomp.explained_variance_ratio_):.2f}')\n",
    "# X_train_transformed = dcomp.transform(X_train.toarray())\n",
    "# X_test_transformed = dcomp.transform(X_test.toarray())\n",
    "# print(f'shape of X_train_transformed: {X_train_transformed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1910ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TruncatedSVD()\n",
    "## n_components=300\n",
    "# 3  itr gave explained variance ratio: 0.41\n",
    "# 15 itr gave explained variance ratio: 0.42\n",
    "\n",
    "## n_components=500\n",
    "# 3  itr gave explained variance ratio: 0.53\n",
    "# 15 itr gave explained variance ratio: 0.53\n",
    "\n",
    "## n_components=1000\n",
    "# 3  itr gave explained variance ratio: 0.71\n",
    "# 15 itr gave explained variance ratio: 0.71\n",
    "\n",
    "## n_components=1500\n",
    "# 3  itr gave explained variance ratio: 0.82\n",
    "\n",
    "\n",
    "# clfs = []\n",
    "# # clfs.append(DecisionTreeClassifier(random_state=42))\n",
    "# clfs.append(ExtraTreesClassifier(n_estimators=10, random_state=42, n_jobs=-1))\n",
    "# clfs.append(RandomForestClassifier(n_estimators=15, random_state=42, n_jobs=-1))\n",
    "# # clfs.append(RadiusNeighborsClassifier(n_jobs=-1))\n",
    "\n",
    "# # clfs.append(KNeighborsClassifier(n_neighbors=10, n_jobs=-1)) # untested\n",
    "\n",
    "# for clf in clfs:\n",
    "#     start = time.time()\n",
    "    \n",
    "#     _ = clf.fit(X_train_transformed, y_train)\n",
    "    \n",
    "#     print(\"Clf: \", clf.__class__.__name__)\n",
    "#     print_score(y_test, clf.predict(X_test_transformed))\n",
    "#     print(f'Train score: {clf.score(X_train_transformed, y_train)}')\n",
    "#     print(f'Test score:  {clf.score(X_test_transformed, y_test)}')\n",
    "\n",
    "#     print(f'Time taken for {clf.__class__.__name__} was {time.time()-start:.2f}\\n\\n')\n",
    "\n",
    "\n",
    "# min score 1... min df 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb91ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "# clfs.append(DecisionTreeClassifier(random_state=42))\n",
    "clfs.append(ExtraTreesClassifier(n_estimators=10, random_state=42, n_jobs=3))\n",
    "clfs.append(RandomForestClassifier(n_estimators=15, random_state=42, n_jobs=3))\n",
    "# clfs.append(RadiusNeighborsClassifier(n_jobs=-1))\n",
    "\n",
    "# clfs.append(KNeighborsClassifier(n_neighbors=10, n_jobs=-1)) # untested\n",
    "\n",
    "for clf in clfs:\n",
    "    start = time.time()\n",
    "    _ = gc.collect()\n",
    "    _ = clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Clf: \", clf.__class__.__name__)\n",
    "    f1 = print_score(y_test, clf.predict(X_test))\n",
    "    print(f'Train score: {clf.score(X_train, y_train)}')\n",
    "    print(f'Test score:  {clf.score(X_test, y_test)}')\n",
    "\n",
    "    print(f'Time taken for {clf.__class__.__name__} was {time.time()-start:.2f}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "440d1258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf:  MLPClassifier\n",
      "Accuracy score: 0.33423887587822015\n",
      "Recall score: 0.5944094165414121\n",
      "Precision score: 0.6495997459270161\n",
      "F1 score: 0.6191668671471201\n",
      "Train score: 0.9959952536339365\n",
      "Test score:  0.33423887587822015\n",
      "Time taken for MLPClassifier was 1801.59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x216 with 0 Axes>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16878645340>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Caution MLPClassifier can take long to train. ')\n",
    "start = time.time()\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(512, 100), random_state=42, max_iter=30)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Clf: \", clf.__class__.__name__)\n",
    "f1 = print_score(y_test, clf.predict(X_test))\n",
    "print(f'Train score: {clf.score(X_train, y_train)}')\n",
    "print(f'Test score:  {clf.score(X_test, y_test)}')\n",
    "    \n",
    "print(f'Time taken for {clf.__class__.__name__} was {time.time()-start:.2f}')\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(clf.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3ba38358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del clfs\n",
    "_=gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0792c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: c#\n",
      "y_test: c#\n",
      "\n",
      "\n",
      "y_pred: \n",
      "y_test: xml\n",
      "\n",
      "\n",
      "y_pred: \n",
      "y_test: class\n",
      "\n",
      "\n",
      "y_pred: ios, objective-c\n",
      "y_test: ios, objective-c\n",
      "\n",
      "\n",
      "y_pred: django, python\n",
      "y_test: django\n",
      "\n",
      "\n",
      "y_pred: \n",
      "y_test: c++\n",
      "\n",
      "\n",
      "y_pred: c#, delphi, winforms\n",
      "y_test: .net, c#, winforms\n",
      "\n",
      "\n",
      "y_pred: android\n",
      "y_test: android\n",
      "\n",
      "\n",
      "y_pred: database, mysql\n",
      "y_test: database, mysql\n",
      "\n",
      "\n",
      "y_pred: ipad\n",
      "y_test: iphone, objective-c, xcode\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test[:])\n",
    "for i in range(5):\n",
    "    idx = np.random.randint(0, len(y_pred))\n",
    "    print(\"y_pred:\",', '.join(mlb.inverse_transform(y_pred[idx].reshape(1,-1))[0]))\n",
    "    print(\"y_test:\",', '.join(mlb.inverse_transform(y_test[idx].reshape(1,-1))[0]))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2030e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.41033567525370807\n",
      "Recall score: 0.5303246208202386\n",
      "Precision score: 0.6853284607898511\n",
      "F1 score: 0.585585014891463\n"
     ]
    }
   ],
   "source": [
    "y_pred_same_number_of_tags = [] # if average tags is 2.5, we are at a disadvantage if we do 2 or 3 tags.\n",
    "for i in range(len(y_pred)):  \n",
    "    best = y_pred[i].argsort()\n",
    "    y_pred_ = np.zeros(y_pred.shape[1])\n",
    "    number_of_tags = np.sum(y_test[i])\n",
    "    y_pred_[best[-number_of_tags:]] = 1\n",
    "    y_pred_same_number_of_tags.append(y_pred_)\n",
    "    \n",
    "_ = print_score(y_test, y_pred_same_number_of_tags) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211c161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy score: 0.9959952536339365\n",
      "Recall score: 0.9989239633364962\n",
      "Precision score: 0.998521101023201\n",
      "F1 score: 0.9987211981852843\n",
      "Test set\n",
      "Accuracy score: 0.33423887587822015\n",
      "Recall score: 0.5944094165414121\n",
      "Precision score: 0.6495997459270161\n",
      "F1 score: 0.6191668671471201\n"
     ]
    }
   ],
   "source": [
    "# without ensuring the same number of tags, we are at a disadvantage if we do 2 or 3 tags.\n",
    "\n",
    "print(\"Train set\")\n",
    "_ = print_score(y_train, clf.predict(X_train)) \n",
    "\n",
    "print(\"Test set\")\n",
    "_ = print_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc7f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "796ead60",
   "metadata": {},
   "source": [
    "## Miscellaneous ending statistics and investigation \n",
    "> out of order execution. note TF-IDF will discrd data. y_train for it can not be assumed to be similar to y_train from tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b76938f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498996 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9    ...  91   92   93   \\\n",
       "0         0    1    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "498991    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "498992    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "498993    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "498994    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "498995    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "        94   95   96   97   98   99   100  \n",
       "0         0    0    0    0    0    0    0  \n",
       "1         0    0    0    0    0    0    0  \n",
       "2         0    0    0    0    0    0    0  \n",
       "3         0    1    0    0    0    0    0  \n",
       "4         0    0    0    0    0    0    0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "498991    0    0    0    0    0    0    0  \n",
       "498992    0    0    0    0    0    0    0  \n",
       "498993    0    0    0    0    0    0    0  \n",
       "498994    0    0    0    0    0    0    0  \n",
       "498995    0    0    0    0    0    0    0  \n",
       "\n",
       "[498996 rows x 101 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.concatenate((y_train, y_test)), index=None)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5137bc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'android'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'java'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'python'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# df.apply(pd.value_counts)\n",
    "\n",
    "value_counts = df.value_counts()[0].index\n",
    "for i in range(3):\n",
    "    tmp = value_counts[i]\n",
    "    tmp = np.array(tmp)\n",
    "    tmp = np.concatenate((np.array([0]), tmp))\n",
    "    mlb.inverse_transform(tmp.reshape(1,-1))[0][0]\n",
    "    \n",
    "    y_pred = np.zeros_like(y_test)\n",
    "    for i in y_pred:\n",
    "        y_pred[i] = tmp\n",
    "    F1=print_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7279627f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tag       \n",
       "java          53895\n",
       "javascript    52490\n",
       "c#            51597\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "next is java\n",
      "Accuracy score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "next is javascript\n",
      "Accuracy score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "next is c#\n",
      "Accuracy score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = tags.value_counts()[:3]\n",
    "# print(top)\n",
    "top = mlb.transform(top.index)\n",
    "\n",
    "ii=0\n",
    "for i in top: \n",
    "    print(f'\\nnext is {tags.value_counts()[:3].index[ii][0]}')\n",
    "    y_pred = np.zeros_like(y_test)\n",
    "    for i in y_pred:\n",
    "        y_pred[i] = top[i]\n",
    "    F1=print_score(y_test, y_pred)\n",
    "    ii=ii+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335496db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqueWords = [] \n",
    "# for q in list_of_questions[:1000]:\n",
    "#     for word in q.split():\n",
    "#       if not word in uniqueWords:\n",
    "#           uniqueWords.append(word);\n",
    "          \n",
    "# len(uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a2dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2ae1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787bdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
